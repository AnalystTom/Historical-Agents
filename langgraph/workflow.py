# -*- coding: utf-8 -*-
"""Copy of debate_agent - amended.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kf_MassRUgjCW-sQXmVysuCJoyAsVkQO
"""

# LangChain + Monto Carlo Search Tree( )
# Tracing  LangSmith,
# Debate search
# Tooling
# Output presentation
# Reduce hallunincatation

from textwrap3 import indent, dedent

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from typing import Any, List, TypedDict
import os
import time
from pymongo import MongoClient
from langchain.text_splitter import CharacterTextSplitter
from sentence_transformers import SentenceTransformer
from datetime import datetime
# Your other imports
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_groq import ChatGroq
from langgraph.graph import MessagesState
from langgraph.graph.state import StateGraph
from langgraph.checkpoint.memory import MemorySaver
from langchain_community.tools import DuckDuckGoSearchResults
# [Add other necessary imports from your original code]


from IPython.display import Image, display, Markdown
import textwrap
import getpass

from typing import Any, Annotated, List, TypedDict
from pydantic import BaseModel, Field

from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.document_loaders import WikipediaLoader
from langchain_community.retrievers import WikipediaRetriever
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.tools import DuckDuckGoSearchResults
from langchain_groq import ChatGroq

from langgraph.graph import MessagesState
from langgraph.graph.state import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph.message import add_messages

# google_api_key = userdata.get('GOOGLE_API_KEY')

# model = ChatGoogleGenerativeAI(model="gemini-1.5-flash",
#                               api_key=google_api_key
#                               )

# # model.invoke("Test")


app = FastAPI()

# Handle CORS (Cross-Origin Resource Sharing)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, specify allowed origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Set your API keys (ensure they are securely stored)
os.environ["TAVILY_API_KEY"] = "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"
os.environ["GROQ_API_KEY"] = "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"


# Initialize the model
model = ChatGroq(
    model="llama-3.2-1b-preview",
    verbose=True,
    temperature=0.5,
    api_key=os.environ["GROQ_API_KEY"]
)

model.invoke('TEST').content

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")


_set_env("TAVILY_API_KEY")

memory = MemorySaver()

# class State(TypedDict):
#   topic: str
#   pro_debator: str
#   anti_debator: str
#   greetings: str
#   planning: str
#   pro_debator_response: str
#   anti_debator_response: str
#   context: Annotated[list, add_messages]
#   debate: Annotated[list, add_messages]
#   debate_history: List[str]
#   iteration: int
#   max_iteration: int

class DebateHistory(BaseModel):
  debate_history: List[str] = Field(description="A variable that stores summary of every debate round")

class AntiDebateResponse(BaseModel):
  anti_debator_response: str = Field(description="The anti-debator's response to the latest argument")

class ProDebateResponse(BaseModel):
  pro_debator_response: str = Field(description="The pro-debator's response to the latest argument")

class State(TypedDict):
  topic: str
  pro_debator: str
  anti_debator: str
  greetings: str
  pro_debator_response: ProDebateResponse
  anti_debator_response: AntiDebateResponse
  context: Annotated[list, add_messages]
  debate: Annotated[list, add_messages]
  debate_history: DebateHistory
  planner: str
  winner: str
  iteration: int
  max_iteration: int

def measure_time(node_function):
    """Decorator to measure and log the execution time of a node function."""
    def wrapper(state, *args, **kwargs):
        start_time = time.time()
        print(f"Starting node: {node_function.__name__}")
        result = node_function(state, *args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time
        print(f"Node {node_function.__name__} completed in {elapsed_time:.2f} seconds.\n")

        # Optionally store in state for later analysis
        if "node_times" not in state:
            state["node_times"] = {}
        state["node_times"][node_function.__name__] = elapsed_time

        return result
    return wrapper

@measure_time
def greeting_node(state: State):
    """LangGraph node that greets the debaters and introduces them"""
    topic = state['topic']
    pro_debator = state['pro_debator']
    anti_debator = state['anti_debator']

    prompt = f"""
    You are a professional and unbiased debate host introducing a debate between two participants:
    - {pro_debator}, who supports the topic.
    - {anti_debator}, who opposes the topic.
    Topic: "{topic}"
    Instructions:
    1. Clearly and briefly introduce the participants and the topic to the audience.
    2. Avoid opinions, commentary, or humor. Maintain a formal and neutral tone.
    3. Do not include information not provided in this prompt. Keep the introduction concise, no more than 3 sentences.
    4. Ensure the output is free from errors or irrelevant content.
    Format:
    - Start by welcoming the audience.
    - Introduce the participants and their respective backgrounds.
    - Introduce the topic of debate like a host.
    """

    greetings = model.invoke(prompt).content
    return {"greetings": greetings}

@measure_time
def planning_node(state: State):
    """LangGraph node that analyzes the latest argument for web search"""
    topic = state['topic']
    pro_debator = state['pro_debator']
    anti_debator = state['anti_debator']
    last_message = state["debate"][-1]
    planning_prompt = None

    system_message = ""

    if isinstance(last_message, HumanMessage):
      print("Planning for Anti Debator")
      planning_prompt = """
        You are an expert in debate strategy. Your task is to help the anti-debator
        {anti_debator} craft
        a compelling counter-argument to the pro-debator's, {pro_debator}, arguments on the debate topic:
        {topic}.
        Here's the information you have:
        * **Pro-Debator's Argument:** {last_message}
        Generate an actionable plan with the following structure:
        **1. Identify Weaknesses:** Analyze the pro-debator's argument. Pinpoint logical
        fallacies, weak points, unsupported claims, or areas where more evidence is needed.
        **2. Research and Evidence Gathering:** Suggest specific research avenues to find
        evidence that refutes the pro-debator's argument.  Provide concrete examples of
        sources and keywords.
        **3. Counter-Argument Formulation:** Outline the main points of a counter-argument.
        Each point should directly address a weakness in the pro-debator's argument and be
        supported by the suggested research.
        **4. Rebuttals:** Anticipate the pro-debator's possible rebuttals and suggest
        preemptive counter-rebuttals.
        **5. Presentation Strategy:** Outline how to present the counter-argument
        effectively:
            * Should the anti-debator focus on emotion or logic?
            * What rhetorical devices would be effective?
            * How to present the evidence concisely and persuasively?
        Example Output:
        **1. Identify Weaknesses:** The pro-debator's argument relies on a study from
        2010, which may be outdated.  They also don't address the economic impact of
        their proposal.

        **2. Research and Evidence Gathering:** Search for more recent studies on the
        topic. Look for economic analyses of similar proposals. Search terms: "[topic]
        economic impact," "[topic] recent studies," etc.  Look for credible sources
        such as peer-reviewed journals.
        **3. Counter-Argument Formulation:**
            * Point 1: The 2010 study is outdated and newer research contradicts its findings.
            * Point 2: The proposal has significant negative economic consequences.
        **4. Rebuttals:** The pro-debator might argue that the newer studies are biased.
        Prepare to address this by presenting evidence of the studies' methodology and
        peer review.
        **5. Presentation Strategy:** Emphasize the economic impact and present the data
        visually. Maintain a logical, calm demeanor. Use statistics and specific examples
        instead of generalizations.

        Ensure the plan is specific to the given information.
      """

      system_message = planning_prompt.format(
          topic=topic,
          anti_debator=anti_debator,
          pro_debator = pro_debator,
          last_message=last_message,
      )

    elif isinstance(last_message, AIMessage):
      # Analysis for an AIMessage (anti-debator's counterargument)
      print("Analyzing for Pro Debator")
      planning_prompt = """
        You are an expert debate strategist tasked with formulating a
        counter-argument
        against an opponent's position on a given topic.  Your goal is to
        create an actionable plan to devise a compelling and effective
        counter-argument for {anti_debator} against {pro_debator}.
        Given the following information:
        1. **Topic:** {topic}
        2. **Anti-Debator's Argument:** {last_message}
        4. **Desired Outcome:** Develop a counter-argument that effectively
        refutes the opponent's claims, strengthens your own position, and
        persuades the audience.


        **Develop an actionable plan that includes the following:**

        * **Identify Key Weaknesses:** Analyze the opponent's argument for
        logical fallacies, weak points, unsupported claims, or inconsistencies.
        List at least 3 key weaknesses.
        * **Research & Evidence Gathering:** Specify relevant areas of research,
        data sources, or examples that can be used to support your counter-argument.
        * **Counter-Argument Formulation:**  Outline the structure of your
        counter-argument.  Include the key points you will make and how they
        directly address the weaknesses identified.
        * **Rebuttals:** Anticipate potential rebuttals from the opponent and
        formulate concise responses.
        * **Presentation Strategy:**  Suggest how to effectively present your
        counter-argument, considering factors such as tone, clarity, and
        persuasive language.
        **Deliverable:** A detailed, step-by-step plan that can be used to
        create a powerful and persuasive counter-argument.
      """
      system_message = planning_prompt.format(
          topic=topic,
          anti_debator=anti_debator,
          pro_debator = pro_debator,
          last_message=last_message
      )
    state['planner'] = model.invoke(system_message).content
    return state

@measure_time
def search_web(state: State):
    """LangGraph node that do a DuckDuckGo search and append the results to context."""
    planner = state['planner']
    last_message = state['debate'][-1]

    prompt = f"""
        You are a search query generator for debate.
        Instructions:
        Based on the provided planning of the latest argument and the
        last message in a debate, generate a concise search query (maximum 8 words)
        focused on retrieving statistical and numerical data relevant to the latest prompt.
        Prioritize queries that are likely to yield objective data.
        Planning:
        {planner}

        Last Message:
        {last_message}
      """
    search_query = model.invoke(prompt).content.strip()

    print("DuckDuckGo Search Query:", search_query)

    search = DuckDuckGoSearchResults(backend="news", output_format='list')
    search_result = search.invoke(search_query)
    result = ""
    for entry in search_result:
        print(entry['snippet'])
        result += entry['snippet'] + "\n"

    state['context'].append(result)
    return {"context": state['context']}

@measure_time
def search_wikipedia(state: State):
    """Retrieve docs from Wikipedia using WikipediaRetriever"""

    planner = state['planner']
    last_message = state["debate"][-1]
    pro_debator = state['pro_debator']
    anti_debator = state['anti_debator']
    topic = state['topic']


    search_query_prompt = ""
    if isinstance(last_message, HumanMessage):
      search_query_prompt = f"""
        You are a search assistant generating a concise search query for Wikipedia.
        Task:
        Find the most relevant wikipedia articles for {pro_debator} related to
        the topic {topic} taking into account the following planning:
        {planner}
        Output format:
        A single concise search query relevant to the topic that has a corresponding name in wikipedia
      """
    elif isinstance(last_message, AIMessage):
      search_query_prompt = f"""
            You are a search assistant generating a concise search query for Wikipedia.
            Task:
            Find the most relevant wikipedia articles for {anti_debator} related to
            the topic {topic}
            Output format:
            A single concise search query relevant to the topic that has a corresponding name in wikipedia
          """

    search_query = model.invoke(search_query_prompt).content.strip()

    print(f'Search Query: {search_query}\n')

    retriever = WikipediaRetriever()

    search_docs = retriever.invoke(search_query)
    print(f'Search Docs: {search_docs}')

    all_summaries = ""
    for doc in search_docs:
        if 'summary' in doc.metadata:
            all_summaries += doc.metadata['summary'] + "\n\n"

    state['context'].append(all_summaries)
    print(f"Updated Context: {state['context']}")
    return state

@measure_time
def pro_debator_node(state: State):
    """LangGraph node that represents the pro debator"""

    topic = state['topic']
    anti_debator_response = state.get('anti_debator_response')
    pro_debator = state['pro_debator']
    anti_debator = state['anti_debator']
    debate_history = state.get('debate_history', [])
    planner = state.get("planner", "")
    debate = state.get('debate', [])
    context = state.get('context', "")

    if not anti_debator_response and not debate:
      # Greeting and opening argument scenario
      prompt_template = """
          You are {pro_debator}, presenting the affirmative stance on the topic: "{topic}" in a debate.
          Your goal is to deliver a strong and concise opening argument in favor of "{topic}" in no more than 3-4 sentences.
          Your language should be conversational, persuasive, and directly relevant to the topic. Avoid lengthy introductions.

          Guidelines:
          1. **Persona Alignment**: Use language and phrases consistent with {pro_debator}'s persona.
          2. **Clarity and Brevity**: Make your opening impactful but keep it conversational and limited to 3-4 sentences.
          3. **Focus on Core Argument**: Present clear and logical points without unnecessary elaboration or excessive detail.
          4. Take into account planning made by the planner {planner}

          **Context (if applicable)**: {context}

          Begin your opening statement.
      """
      system_message = prompt_template.format(
          pro_debator=pro_debator,
          anti_debator=anti_debator,
          planner=planner,
          topic=topic,
          context=context
      )
    else:
      # Responding to latest argument scenario
      prompt_template = """
        You are {pro_debator}, presenting your affirmative stance on the topic:
        "{topic}" in a debate.
        Your task is to directly respond to the latest argument by {anti_debator}
        in a concise and conversational manner, limited to 3-4 sentences.
        Focus on addressing weaknesses, logical fallacies, or gaps in their
        argument while maintaining a persuasive tone.

        Guidelines:
        1. **Direct Rebuttal**: Address the latest response from {anti_debator}
        directly.
        2. **Persona Alignment**: Use language and phrases consistent with
        {pro_debator}'s persona.
        3. **Clarity and Brevity**: Keep your response impactful but limited
        to 3-4 sentences.
        4. **Avoid Redundancy**: Leverage details from the debate history to
        strengthen your response without repeating previous arguments.
        5. **Use Context**: Use relevant details from the context or debate
        history (if applicable) to make your argument more credible.
        6. Take into account planning made by the planner {planner}

          **Debate History**:
        {debate_history}

        **Latest Argument from {anti_debator}**:
        {anti_debator_response}

        **Context**:
        {context}

        Craft your rebuttal.
      """
      system_message = prompt_template.format(
          pro_debator=pro_debator,
          topic=topic,
          anti_debator=anti_debator,
          debate_history=debate_history,
          anti_debator_response=anti_debator_response,
          context=context,
          planner=planner
      )

    pro_debator_response_content = model.invoke(system_message).content

    pro_debator_response = HumanMessage(
        content=f"{pro_debator}: {pro_debator_response_content}",
        name="pro_response"
    )

    debate.append(pro_debator_response)
    return {"pro_debator_response": pro_debator_response, "debate": debate}

@measure_time
def anti_debator_node(state: State):
    """LangGraph node that represents the anti debator"""
    topic = state['topic']
    anti_debator_response = state.get('anti_debator_response')
    pro_debator = state['pro_debator']
    anti_debator = state['anti_debator']
    debate_history = state.get('debate_history', [])
    debate = state.get('debate', [])
    context = state.get('context', "")
    planner = state.get('planner', "")

    # Improved prompt with guardrails
    prompt_template = """
        You are {anti_debator}, presenting your opposing stance on the topic: "{topic}" in a debate.
        Your task is to craft a direct and concise rebuttal to the latest argument provided by {pro_debator}.
        The opinion should reflect a real stance that {anti_debator} has taken on the topic "{topic}" and align with their persona.

        Guidelines for crafting your rebuttal:
        1. **Direct Rebuttal**: Respond specifically to the latest argument from {pro_debator}. Address any logical flaws, missing evidence, or weak points while maintaining a respectful tone.
        2. **Clarity and Brevity**: Limit your response to no more than 3 sentences. Ensure it is conversational, impactful, and easy to follow.
        3. **Debate Continuity**: Use relevant details from the debate history (if provided) to strengthen your response while avoiding redundancy.
        4. **Persona Consistency**: Use language, phrases, and tone that align with {anti_debator}'s persona and style of communication.
        5. **Guardrails**: Avoid unsupported claims, personal attacks, or unrelated points. Stick to the topic and present logical arguments.
        6. **Use of Context**: Incorporate credible evidence or insights from the provided context (if applicable) to make your argument more persuasive.
        7. Take into account planning made by the planner {planner}

        **Context (if applicable)**:
        {context}

        **Debate History (recent exchanges)**:
        {debate_history}

        **Latest Argument from {pro_debator}**:
        {pro_debator_response}

        **Your Rebuttal**:
    """

    # Generate the system message for the model
    system_message = prompt_template.format(
        topic=topic,
        pro_debator=pro_debator,
        pro_debator_response=anti_debator_response,
        anti_debator=anti_debator,
        debate_history=debate_history,
        context=context,
        planner=planner
    )

    anti_debator_response_content = model.invoke(system_message).content

    anti_debator_response = AIMessage(
        content=f"{anti_debator}: {anti_debator_response_content}",
        name="anti_response"
    )

    debate.append(anti_debator_response)
    return {"anti_debator_response": anti_debator_response, "debate": debate}

@measure_time
def debate_summarizer_node(state: State):
  """LangGraph node that summarizes the exchange of arguments between debator
  and append to history for future consideration
  """
  pro_debator = state['pro_debator']
  anti_debator = state['anti_debator']
  debate_history = state['debate_history']
  anti_debator_response = state['anti_debator_response']
  pro_debator_response = state['pro_debator_response']
  prompt = """
            Summarize the conversation between the pro {pro_debator} and anti debator {anti_debator},
            highlighting the key points of their arguments and discarding unnecessary points. The
            summary should be concise and brief, with high quality.
            **Instructions:**
            * Focus on the core arguments presented by both sides.
            * Identify the main points of agreement and disagreement.
            * Provide a clear and objective overview of the debate.
            * Avoid including irrelevant details or repetitive information.
            * Ensure that the summary is easy to understand and informative.
            **Pro Debator:**
            {pro_debator_response}
            **Anti Debator:**
            {anti_debator_response}
          """
  system_message = prompt.format(
                      pro_debator=pro_debator,
                      pro_debator_response=pro_debator_response,
                      anti_debator=anti_debator,
                      anti_debator_response=anti_debator_response,
                    )
  summary = model.invoke(system_message).content
  debate_history.append(summary)
  state['debate_history'] = debate_history
  state['iteration'] += 1
  print(f"Updated Iteration: {state['iteration']}")
  return state

@measure_time
def winner_decider_node(state: State):
  """LangGraph node that determines the winner of the debate"""
  debate_history = state['debate_history']
  prompt = """
    You are an AI judge tasked with determining the winner of a debate between
    two debaters based on their debate history.
    Analyze the provided debate history and determine which debater presented
    more logical and compelling arguments.

    Consider the following criteria:

    * **Logical consistency:** Does the debater's argumentation follow a clear
    and consistent line of reasoning? Are there any internal contradictions or
    logical fallacies?
    * **Evidence and support:** Does the debater provide sufficient evidence and
    support for their claims? Are the sources credible and relevant?
    * **Rebuttals and counterarguments:** How effectively does the debater
    address the opponent's arguments? Do they offer strong rebuttals and
    counterarguments?
    * **Clarity and persuasiveness:** Is the debater's communication clear,
    concise, and persuasive? Do they effectively convey their points to the
    audience?
    * **Overall impact:** Which debater's arguments had a greater overall impact
    and persuaded you more effectively?

    Debate History:
    {debate_history}

    Based on the debate history, who presented the more logical and stronger arguments: {pro_debator} or {anti_debator}?  Explain your reasoning by referencing specific instances from the debate history.  Provide a concise summary of why you chose the winner.  Do not simply restate the arguments.
  """
  system_message = prompt.format(
    debate_history=debate_history,
    pro_debator=state['pro_debator'],
    anti_debator=state['anti_debator']
  )
  winner = model.invoke(system_message).content
  return {"winner": winner}

def router(state: State):
    """LangGraph node that routes to the appropriate search function"""
    debate_history = state["debate_history"]
    if debate_history == []:
        return "Pro Debator"
    else:
      return "Planner"


def iteration_router(state: State):
    """Routes the flow based on the current iteration and max_iteration"""
    if state['iteration'] >= state['max_iteration']:
        print("Ending the debate as max iteration is reached.")
        return "Winner Decider"
    print(f"Iteration Round: {state['iteration']}")
    state['iteration'] += 1
    return "Planner"


def analyzer_router(state: State):
    """Function that routes to the appropriate next node"""
    debate = state['debate']
    last_message = debate[-1]
    if isinstance(last_message, AIMessage):
        return "Pro Debator"
    else:
        return "Anti Debator"



builder = StateGraph(State)
# Add nodes
builder.add_node("Greetings", greeting_node)
builder.add_node("Pro Debator", pro_debator_node)
builder.add_node("Planner", planning_node)
#builder.add_node("Search Web", search_web)
builder.add_node("Search Wikipedia", search_wikipedia)
builder.add_node("Anti Debator", anti_debator_node)
builder.add_node("Debate Summarizer", debate_summarizer_node)
builder.add_node('Winner Decider', winner_decider_node)

# Add edges
builder.add_edge(START, "Greetings")
builder.add_conditional_edges("Greetings", router, ['Planner', 'Pro Debator'])
#builder.add_edge("Planner", "Search Web")
builder.add_edge("Planner", "Search Wikipedia")
#builder.add_conditional_edges("Search Web", analyzer_router, ["Pro Debator", "Anti Debator"])
builder.add_conditional_edges("Search Wikipedia", analyzer_router, ["Pro Debator", "Anti Debator"])


builder.add_edge("Pro Debator", "Planner")
builder.add_edge("Anti Debator", "Debate Summarizer")
builder.add_conditional_edges(
    "Debate Summarizer",
    iteration_router,
    ["Planner", "Winner Decider"]
)
builder.add_edge("Winner Decider", END)

debator = builder.compile(checkpointer=memory).with_config(run_name="Starting Debate")

@app.post("/trigger_workflow")
async def trigger_workflow(request: Request):
    data = await request.json()
    debate_topic = data.get('debate_topic')
    debater1 = data.get('debater1')
    debater2 = data.get('debater2')
    max_iterations = data.get('max_iterations', 1)

    # Initialize state
    state = {
        "topic": debate_topic,
        "pro_debator": debater1,
        "anti_debator": debater2,
        "greetings": "",
        "planning": "",
        "pro_debator_response": None,
        "anti_debator_response": None,
        "context": [],
        "debate": [],
        "debate_history": [],
        "iteration": 0,
        "max_iteration": max_iterations
    }

    # Add the required 'configurable' keys
    thread = {"configurable": {"thread_id": "unique_id", "recursion_limit": 100}}

    # Run the debate agent
    result = debator.invoke(state, thread)

    # Prepare the conversation history in JSON format
    conversation = []
    if result['pro_debator_response']:
        conversation.append({
            'speaker': debater1,
            'content': result['pro_debator_response'].content
        })

    if result['anti_debator_response']:
        conversation.append({
            'speaker': debater2,
            'content': result['anti_debator_response'].content
        })



    if result.get('winner'):
        conversation.append({
            'speaker': "Winner Decider",
            'content': result['winner']
        })

    response = {
        'greetings': result['greetings'],
        'conversation': conversation
    }

    return response


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
